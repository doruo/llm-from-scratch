# llm from scratch

An AI LLM prototype written in plain python, only for personnal educational purpose. WORK IN PROGRESS.

It is a Generatively Pretrained Transformer (GPT), following the paper ["Attention is All You Need"](https://arxiv.org/abs/1706.03762) and OpenAI's [GPT-2](https://huggingface.co/openai-community/gpt2) / [GPT-3](https://fr.wikipedia.org/wiki/GPT-3).

It was made for educationnal purpose only and understanding what is happening under the hood.

<strong> No AI were used in any of the project nor code. </strong>

I tried to learn and resume a course based on those two great videos :

- [Andrej Karpathy - Let's build GPT: from scratch, in code, spelled out.](https://www.youtube.com/watch?v=kCc8FmEb1nY)

- [freeCodeCamp.org - Create a Large Language Model from Scratch with Python â€“ Tutorial](https://www.youtube.com/watch?v=UU1WVnMk4E8)

Using these tools : 

- Python Anaconda, langage distribution made for research and deep-learning

- Ipykernel, for handling python3 kernels with virtual environments

- Pytorch, an optimized tensor library for deep learning

- CUDA, for parallel GPU computing

- Jupyter, for python notebooks

## Setup

```bash
bash setup.sh
```

## Launch 

```bash
bash run.sh
```
