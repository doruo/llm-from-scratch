{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5bc47e2",
   "metadata": {},
   "source": [
    "# LLM Course\n",
    "\n",
    "We build a Generatively Pretrained Transformer (GPT), following the paper \"Attention is All You Need\" and OpenAI's GPT-2 / GPT-3.\n",
    "\n",
    "This course was possible by the help of those two videos :\n",
    "\n",
    "- [Andrej Karpathy - Let's build GPT: from scratch, in code, spelled out.](https://www.youtube.com/watch?v=kCc8FmEb1nY)\n",
    "\n",
    "- [freeCodeCamp.org - Create a Large Language Model from Scratch with Python – Tutorial](https://www.youtube.com/watch?v=UU1WVnMk4E8)\n",
    "\n",
    "It was made for educationnal purpose and understanding what is happening under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f4fcbc",
   "metadata": {},
   "source": [
    "## Tokenizer and character vocabulary\n",
    "\n",
    "First, we read a book file to create our vocabulary. It will then be used to train the model.\n",
    "\n",
    "We create with this a tokenizer that is divided in two parts : \n",
    "\n",
    "- encode text into integers sorted set, \n",
    "\n",
    "- and decode integers input into original text.\n",
    "\n",
    "This tokenizer works with char-level tokenizing, it means that in each prompt, it will encode each character. It is not the most efficient, but we are gonna stay on char-level to simplify the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db62dc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"'()*+,-./0123456789:;<>?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]abcdefghijklmnopqrstuvwxyz£﻿\n"
     ]
    }
   ],
   "source": [
    "# Rename it if you want to try on entire book content\n",
    "file_name = \"./data/journey_to_the_center_of_the_earth.txt\"\n",
    "\n",
    "# Fetch book content\n",
    "fd = open(file_name, encoding=\"utf8\")\n",
    "file_content = fd.read()\n",
    "\n",
    "vocab = sorted(set(file_content))\n",
    "\n",
    "def string_to_int(): \n",
    "   return { char:i for i, char in enumerate(vocab) }\n",
    "\n",
    "def int_to_string():\n",
    "   return { i:char for i, char in enumerate(vocab) }\n",
    "\n",
    "def encode(chars):\n",
    "   return [ string_to_int()[c] for c in chars ]\n",
    "\n",
    "def decode(integers):\n",
    "   return ''.join([ int_to_string()[i] for i in integers ])\n",
    "\n",
    "print(''.join(vocab))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7028702",
   "metadata": {},
   "source": [
    "Here is an application example of the tokenizer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86a1590b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER\n",
      "Encoded data: [83, 30, 35, 28, 43, 47, 32, 45]\n",
      "Decoded data: ﻿CHAPTER\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = file_content[:8]\n",
    "\n",
    "print(data)\n",
    "print (\"Encoded data:\", encode(data))\n",
    "print (\"Decoded data:\", decode(encode(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fffe3b2",
   "metadata": {},
   "source": [
    "## Training and prediction \n",
    "\n",
    "We splits data into prediction and validation, because we do not want to make the model to copy exactly the content of data, but try to product content similar to the data, not the exact one. \n",
    "\n",
    "So we never feed the entire data into the transform, but chunks of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d2ac67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[83, 30, 35, 28, 43, 47, 32, 45]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent = 90 # Cut data into 90% / 10%\n",
    "n = int(len(data) * (percent/100))\n",
    " \n",
    "train_data = data[:n]\n",
    "validation_data = data[n:]\n",
    "\n",
    "block_size = 8\n",
    "train_data[:block_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a9884ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~\n",
      "x chunk: ﻿CHAPT\n",
      "y chunk CHAPTE\n",
      "~~~~~~~~~~~~~~~~~~~\n",
      "-------\n",
      "Step 0\n",
      "Context: [﻿], target: [C]\n",
      "-------\n",
      "Step 1\n",
      "Context: [﻿C], target: [H]\n",
      "-------\n",
      "Step 2\n",
      "Context: [﻿CH], target: [A]\n",
      "-------\n",
      "Step 3\n",
      "Context: [﻿CHA], target: [P]\n",
      "-------\n",
      "Step 4\n",
      "Context: [﻿CHAP], target: [T]\n",
      "-------\n",
      "Step 5\n",
      "Context: [﻿CHAPT], target: [E]\n"
     ]
    }
   ],
   "source": [
    "percent = 0.9 # Splits data\n",
    "n = int(len(file_content) * percent)\n",
    " \n",
    "train_data = file_content[:n+1] # first 90%\n",
    "validation_data = file_content[n:] # remaining 10%\n",
    "\n",
    "block_size = 6\n",
    "\n",
    "xChunk = train_data[:block_size]\n",
    "yChunk = train_data[1:block_size+1]\n",
    "\n",
    "print (\"~~~~~~~~~~~~~~~~~~~\")\n",
    "print(\"x chunk:\",xChunk)\n",
    "print(\"y chunk\", yChunk)\n",
    "print (\"~~~~~~~~~~~~~~~~~~~\")\n",
    "\n",
    "context = \"\"\n",
    "target = \"\"\n",
    "for i in range(block_size):\n",
    "    context = xChunk[:i+1]\n",
    "    target = yChunk[i]\n",
    "\n",
    "    print(\"-------\")\n",
    "    print(\"Step\", i)\n",
    "    print(\"Context: [\"+context+\"], target: [\"+target+\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35136d81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
